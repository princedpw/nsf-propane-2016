\section{Introduction}

All sectors of society depend on properly functioning networks.  Further, both the complexity and requirements of these networks are increasing as more devices come online and richer data and services move to the cloud.  Unfortunately, network errors routinely lead to costly downtime~\cite{mahajan+:bgp-misconfiguration,feamster+:rcc,batfish,dc-failure-study}.
Figure~\ref{fig:network-downtime} reports the results of a Juniper
study on network outages.  It shows that human error, which often occurs in configuration, update, or planned maintenance of networks, is the single largest cause of outages. 
Anecdotally, the evidence is equally compelling.  For instance, recent misconfigurations at
Time Warner led to an hour-long, nation-wide outage of their backbone network~\cite{time-warner} and at United led to temporary suspension of all US flights in July 2015~\cite{united}.

One fundamental reason for these misconfigurations is the
mismatch between the intended high-level
policies and the low-level configurations.  On the one hand, most routing policies involve
network-wide properties:  never announce a particular destination externally, isolate two subnetworks from one another, prefer traffic through a transit customer over a transit provider, etc.
On the other hand, these policies must be implemented via hundreds of low-level configuration directives at each individual router in the network.  Typically, operators do their job by manually
decomposing their network-wide policy into a set of low-level configurations,
one per device.  As a result, errors range from simple consistency issues (community values do not match) to more subtle scenarios (misconfigured ACLs causing intermittent disconnectivity)~\cite{feamster+:rcc,batfish}.

%\begin{figure}[t]
\begin{wrapfigure}{R}{0.4\textwidth}
  \centering
%  \includegraphics[width=.45\textwidth]{figures/errors1}
%  \hspace{1cm}
  \includegraphics[width=.35\textwidth]{figures/errors2} \\
%  (a)  \hspace{3in} (b)
  \caption{
%Two studies on network downtime:  (a) From the Yankee group (2002),
%roughly 60\% of network downtime is caused by human error; (b) 
A Juniper study (2008): 50-80\% of outages are the result of human error.}
  \label{fig:network-downtime}
\end{wrapfigure}
%\end{figure}

% It is well known that the fundamental problem is caused by programming individual router configs device by device to implement a network-wide policy, and % this process, like assembly language coding, is fraught with peril.  Common errors in manual BGP configuration setting range from simple consistenc
 % % (community values do not match) to complex reasoning (failure In backup only triggered after failure). 
%Networks are highly complex, distributed systems that often involve both 
%hardware and software, hundreds, thousands or more different devices, and
%many different interacting protocols and services.
%For years, we have known that managing and configuring
%such systems reliably is extremely difficult and yet crucial to our modern
%economy, government, national defense, and everyday life.  
%While there are many different causes of network downtime, ranging
%from hardware errors to power failures to bugs in embedded software,
 %A few years ago, YouTube was taken
%offline for two hours when Pakistan Telecom erroneously claimed to be
%a legitimate destination for YouTube traffic, and Hong Kong-based
%PCCW, which services Pakistan Telecom failed to drop the erroneous
%messages~\cite{pakistan-youtube}.  Before that, a Turkish telecom
%pretended to be the entire internet~\cite{pakistan-youtube}.  More generally,
%network outages serious enough to make international news continue to
%happen with great regularity~\cite{bgpmon}.

%% The solution to these problems is easy to state:
%% Simply have human operators do less of the work.  The challenge is how?  

%% \begin{quote}
%% Our central idea is to fundamentally change the level of abstraction at which
%% complex networks are configured, lifting it substantially, and having a compiler
%% fill in all of the low-level details, and finally verifying the correctness of our results.
%% \end{quote}

%% At the moment, configuring

%% Rather than have network administrators configure
%% the details of low-level protocols independently on device after device, allow administrators to
%% state the high-level properties

%One fundamental reason for these misconfigurations is the
%semantic mismatch between the intended high-level
%policies and the low-level configurations.
 %Moreover, these individual device configurations often involve more than
%one protocol, such as BGP (the Border Gateway Protocol for communicating routes between different
%autonomous systems) and OSPF (an
%intra-domain protocol for routing along shortest paths in one's own network) the protocols interact with one another.  
%In order to determine whether or not the high-level goals of a user's network-wide policy have been satisfied,
%one must reason about the interaction of protocols on individual devices and the interaction of different devices.
%In essence, the problem is akin to programming a complex, heterogenous distributed system in several
%different, low-level assembly languages, and then checking that one's high-level semantic goals have been met.

To make matters worse, networks must continue to function properly when node and link failures occur.  
%In many contexts, such as in a data center,
%there are so many devices, that failures are inevitable and frequent.  
Unfortunately, network engineers
can, at their very best, reason about their policy in the face of a very small number of failure 
scenarios.  As a result, configurations that work
correctly in failure-free environments have nonetheless been found to violate key
network-wide properties in the presence of failures~\cite{batfish}.
Finally, the described problems of network configuration affect not only the robustness of deployed networks but also the agility of an organization in making the not-infrequent larger-scale changes that are required (extending the network, upgrading equpiment, migrating to a new network architecture).

A natural solution to these problems, analogous to the trend in languages for software development over the last several decades, is to define a higher-level language for implementing desired network policies.  
% Indeed, this solution has been pursued by prior work, yet none of these languages have been widely deployed to date.  An early attempt, Routing Policy Specification Language (RPSL) was not sufficiently high level, still requiring users to manually decompose network-wide policies into router-specific configuration~\cite{rpsl}.  
Indeed, in recent years, researchers have developed a series of network-wide policy 
languages that target  software-defined networking (SDN) platforms for logically centralized control planes, such as OpenFlow~\cite{frenetic,flowlog,foster:merlin,vericon,sagiv:l,fattire,netkat,kinetic,sdn-languages}. These languages have developed intuitive high-level abstractions for specification
of routing policy and developed algorithms that take care of many of the nitty-gritty details of
generating a low-level implementation, thereby avoiding the errors caused by
ad hoc manual configuration.
Unfortunately, these solutions do not apply to the large number of commercial clouds and 
enterprise networks that have invested in, and continue to use, distributed control planes and 
traditional routers.  Moreover, most of the academic projects that use centralized control 
infrastructure are not fault tolerant nor do they help users control inter-domain routing
policy (routing between one's network and a neighbor), which occupies a significant portion of route
configuration complexity.  In other words, there are many pragmatic hurdles to surmount before
they may be deployed in many industrial settings.
%Moreover, while such languages facilitate specification of intra-domain
%routing policy (routing within one's network), they do not help users control inter-domain routing
%policy (routing between one's network and a neighbor), which occupies a significant portion of route
%configuration complexity.



In a nutshell,
the overarching goal of this project is to find 
\emph{a highly reliable path for deployment of
high-level network abstractions} invented over recent years, and to invent new ones 
where network operators need them.
More specifically, to prepare for this proposal, the PIs have recently developed a 
new network programming language called Propane~\cite{beckett+:propane} (winner of SIGCOMM 2016
best paper award) that borrows from SDN languages an expressive set of primitives for specifying the allowed network-wide paths.  Propane further extends these capabilities to enable the specification of backup paths via a simple form of path preferences, and allows the expression of both intra-domain 
and inter-domain routing objectives.  Crucially, rather than compiling to OpenFlow,
Propane compiles to BGP, the industry-standard and ubiquitous inter-domain routing protocol.  In addition to being an industry standard, BGP is distributed, fault tolerant
and scalable.
However, despite its advances, it is impossible to deploy Propane in pragmatic settings
at the moment for several fundamental reasons:

%Analogous to languages like RPSL, the Propane compiler automatically produces configurations for each router that leverage BGP to implement the desired policy.  Furthermore, the Propane compiler guarantees that the specified path preferences will be respected regardless of the link or node failures that may occur.
%And yet, Propane in its current form is not suitable for widespread deployment.  

%Propane suffers from several deficiencies that also plague the prior work and 
%must be addressed in order to make network programming languages a viable alternative 
%to the current state of the art:

\begin{description}
\item[expressiveness]  Despite their challenges, today's low-level configuration languages provide fine-grained control over network functionality and performance.  Operators will not move to higher-level, network-wide policy languages unless they can express the subtle and complex policies that business requirements demand.  Propane's current 
abstractions on their own do not yet provide a sufficiently wide range of
behaviors.

\item[intelligibility] At least in the near term, the low-level configurations output by the Propane compiler must be human readable and match the configuration styles in use today.  This requirement has become clear in the PIs discussions with network engineers at two large cloud providers.  It is necessary to give them confidence in the behavior of their networks, enable the configurations to be processed with a variety of existing tools, and allow operators to directly modify and debug configurations when necessary.  
% For instance, Network operators, especially for large, structured networks such as data centers, do not think in terms of individual devices.  Instead, they craft policy in terms of \emph{sets} of devices that
% play similar roles such as top-of-rack switch, tier-one switch, \etc and the more general \emph{topological invariants} that connect these sets (\eg, the number of edges or paths that connect elements of each set).  The output of deployable synthesis must match the cognitive models used by network operators.

\item[migration safety]  If an operator's current network is operating smoothly,
migration to a new management platform is a risk, even if that new platform
offers improved efficiency and lower future management costs.  To reduce the
risk, tools that faciliate migration and verify that new high-level policy is
functionally equivalent to old legacy deployments are necessary.

\item[incrementality] No large network is likely to switch from manual configuration to Propane in one ``flag day."   Rather, support for {\em incremental deployment} is critical, with parts of the network gradually moving to this new discipline over time.

\end{description}

%Hence, in the proposed project, we plan to design, study, build and evaluate a new platform 
%capable of (1) synthesizing multi-protocol, distributed control planes from high-level end-to-end specifications,
%and (2) helping users reliably transition from their legacy configurations to our new system.  More specifically,
%our platform will contain the following components:
%\begin{enumerate}
%\item {\bf A high-level language} with a natural and \emph{uniform} set of abstractions
%for jointly specifying \emph{intra-domain} routing constraints, \emph{inter-domain}
%routing constraints and possible \emph{back-up paths} in case of failures.
%\item {\bf Tools for automatic synthesis} of low-level, device-by-device configurations of standard
%distributed control plane algorithms from the high-level language specifications.
%\item {\bf Tools for translation of legacy configurations} into the intermediate language of our compiler.
%\item {\bf Algorithms for verification} that low-level configurations correctly implement high-level %specifications.
%The low-level configurations may have been synthesized from high-level specifications, in which case
%verification helps to double-check the correctness of our synthesis toolchain, giving network operators more
%confidence in our system.  Alternatively, the low-level configurations may have been
%translated from legacy configurations, in which case verification can help find bugs in the legacy configuration,
%or help port the legacy configuration to our new system by validating the equivalence of the legacy %configuration with 
%a new high-level specification.
%\end{enumerate}

%In order to demonstrate the feasibility of our core ideas, in preparation for this proposal, 
%we have already begun to build a prototype system called
%\Propane~\cite{beckett+:propane}. Borrowing linguistic ideas from several recent SDN languages~\cite{fattire,foster:merlin,netkat},
%\Propane users specify policy using high-level path constraints, defined using regular expressions and predicates.

%\emph{Unlike} previous SDN-oriented languages, \Propane supports the ability to specify \emph{back-up paths}, which allow users 
%to express preferences
%between routes and to indicate desired behavior in the presence of faults, and more importantly, \Propane{} does not use a 
%centralized controller.  Instead, the \Propane{}
%compiler synthesizes a collection of BGP configurations, which are used to configure conventional routers.  As such, the 
%implementation is:  (1) fully distributed, 
%(2) operates using completely standard, widely-deployed, legacy protocols, (3) can manage both intra-domain and inter-domain routing,
%(4) is highly scalable, having been used at data center and internet-scale, and (5) is fault tolerant, %offering local fault 
%detection and recovery.  However, our initial prototype supports limited user abstractions, only synthesizes configurations for a 
%single protocol (BGP), does not support verification and does not help users transition from legacy configurations to new \Propane-managed
%configurations or update their existing \Propane-managed configurations.

\paragraph*{Intellectual Merit.}
Our goal in this proposal is to develop the techniques and associated tools
to support {\em deployable configuration synthesis}.  Building on our preliminary work, we will develop a new platform called \Name that addresses the deficiencies described above.  Our research has several main thrusts:

\begin{enumerate}

\item {\bf Policy Specification Abstractions:} Network operators typically craft policy in terms of \emph{sets} of devices that
play similar roles in the network (e.g., top-of-rack switches, border routers, \etc) and the  \emph{topological invariants} among these sets (\eg, the number of edges or paths that connect elements of each set).  We will devise new abstractions that allow network engineers to easily define such roles and specify policy in terms of them.  We will then develop compilation techniques that respect these roles, producing one {\em configuration template} per role which can be instantiated to produce the concrete configurations for each device.  
%This technique will ensure that output configurations match both the cognitive models of network engineers and their existing approach of manually implementing per-role configuration templates.  
In addition to making policies more \emph{expressive},
they will make the results of compilation more \emph{intelligeible}, allowing
network operators to examine a small number of templates
rather than a vast number of individual configurations.

\item {\bf Expressivity:} We will study the kinds of routing policies that are in common use for enterprises, data centers, and ISPs~\cite{routingplaybook} and develop new language mechanisms for declaratively expressing such policies.  A key new focus will be on inter-domain routing and specification of \emph{financial transit contracts} and \emph{networking costs}.
By incorporating costs and contracts into inter-domain routing specifications,
the underlying implementation can optimize its use of internet peers.

\item {\bf Backend Diversity:} There is no ``one size fits all'' networking protocol. Propane policies compile solely to BGP, but the additional expressiveness described above, along with performance requirements and the preferences of network engineers, will demand that configurations employ multiple protocols, as is standard for manual configurations today.  We will develop algorithms that synthesize configurations employing a combination of \emph{inter-domain routing} protocols such as BGP and \emph{intra-domain routing protocols} such as OSPF and RIP.  We will also target
\emph{SDN-oriented protocols} such as OpenFlow~\cite{openflow}, P4~\cite{P4} and PIFO~\cite{pifo}, allowing networks to more easily adopt this technology when appropriate, and 
without operators necessarily needing to change high-level policy specifications.

\item {\bf Migration Abstractions:} We will develop approaches to help network engineers migrate existing configurations to network-wide policies.  First, we will develop new algorithms to translate legacy configurations into the intermediate language supported by the \Name language.  Second, we will leverage modern constraint solvers to automatically compare such configurations with a proposed high-level policy, either proving equivalence or providing counterexamples that guide policy refinement.  Third, we will explore techniques to automatically infer network-wide policies directly from the legacy configurations.

\item {\bf Mixed Verification:} Finally, we will develop approaches to support a mixed form of configuration, whereby some portions of the network behavior are specified with \Name and some using existing technologies.  Supporting manual configurations is essential to enable incremental deployment but also to allow an escape mechanism to specify behaviors outside the capability of \Name (just as higher-level languages allow calls to native code).  We envisage adopting and extending the notion of {\em assume-guarantee reasoning} from the literature on compositional program analysis~\cite{Jones:assume-guarantee} to support verification and synthesis for mixed configurations.  
\end{enumerate}

\tdm{This is a nice idea but I'm not sure where it fits.}
{\em Second, we will develop new algorithms that allow the \Name platform to synthesize
updates to low-level network configurations given a pair of old and new \Name specifications, as well as a \emph{plan} to update network devices to
safely transition the system from old configuration to new configuration while the system is in operation.}

\paragraph{The Team.}  Our team has the breadth of skills, backgrounds, and perspectivesthat will be required to accomplish the agenda set out above.  
Over the last 8 years, David Walker and his collaborators
developed the first high-level SDN programming languages, including
Frenetic~\cite{frenetic}, Pyretic~\cite{pyretic} and NetKAT~\cite{netkat}.
He also developed the concept of consistent network updates~\cite{reitblatt+:consistent-updates}
and contributed to the design of P4~\cite{P4}.   Todd Millstein is an expert in automated software verification as well as techniques for static and dynamic program analysis.  He has been applying and extending these approaches to reason about various aspects of networks for more than ten years.  This proposal particularly leverages his expertise in automated verification of low-level network configurations~\cite{batfish}.  George Varghese won the 2014 SIGCOMM lifetime award for his work on routers.  in the last 5 years, he has helped, with the other PIs and colleagues, create the field of network verification.  He has helped create open source verification tools for networks including Header Space Analysis~\cite{hsa} and Network Optimized Datalog (NoD)~\cite{nod}. NoD has been used by Amazon to create verification tools for customer-created virtual networks.  Together, the PIs cover the full spectrum of Network Verification from semantics and synthesis (Walker) to bottom-up verification (Millstein, Varghese).

\paragraph{Broader Impacts.}  
Our economy, businesses, governmental and military infrastructure all depend upon having networks that function
reliably.  
%Unfortunately, current network configuration languages are
%terribly complex and difficult to reason about.  Consequently,
%operators all-too-often make mistakes when programming this critical
%infrastructure.  
The primary goal of this proposal is to develop
a path for deployment of high-level network programming abstractions
improves the reliability of existing legacy networks and helps
transition those networks in a safe and reliable way to new management systems.

{\bf Cloud Deployment:}  We will focus on two major clouds: Microsoft Azure and Google.  All 3 PIs have a strong connection with Microsoft.  Walker via student Ryan Beckett translated a number of Azure policies into Propane in 2015 and validated his models with operators. Millstein recently won the MSR outstanding collaborator award; Varghese worked at MSR from 2012-2016; Albert Greenberg, head of Azure, is open to collaborating with the team.   

We will also seek to deploy at Google: both Walker and Varghese have collaborated with Amin Vahdat the head of networking at Google.  These two clouds are different because Azure is a public cloud while the Google cloud supports Google services; adding abstractions that cover both user cases will be an important step towards credibility.  Collaboration will be done (as with Ryan Beckett and Ari Fogel) via students who will intern at Microsoft and Google

{\bf Broader Outreach:}  While Microsoft and Google will teach us a great deal, we need to learn policies from a broader set of networks.  In order to maximize the effectiveness of our proposed and make a broader
impact, we must educate both students and industry alike.  To do so,
we will engage in industry outreach, by organizing a workshop under
the umbrella of the newly-formed
Cornell-Princeton Center for Network Programming (CNP)~\cite{center-for-network-programming}.
Modelled after the inaugural CNP summit in New York, which drew roughly 50
invitation-only participants from the North-East, including industry participants
from networking, hardware, software and financial companies, our workshop will 
all academics to engage with industry via panel
discussions, technical talks and informal discussions.  

%As we have done in the development of our prior work on Propane~\cite{beckett+:propane} as well as tools such as Batfish~\cite{batfish}, we will obtain iterative feedback from network engineers and operators to ensure that our research results will meet their needs.  Indeed, Batfish identified serious misconfiguration errors in several real-world enterprise and cloud networks that were subsequently fixed.  Also as in our prior work, we will make our tools publicly available for use by other researchers and practitioners.

{\bf Education:} We also plan on having educational impact in various ways.  
The PIs have a track record of engaging undergraduates in research, often resulting in publications.  This project will allow us to engage undergraduates in interdisciplinary
research that applies programming language techniques, such as
automated verification and optimizing compilation, to problems in the networking domain.  At the graduate
level, we will introduce a unit on network programming with high-level
abstractions to our core
graduate courses on programming languages and semantics.  Varghese and Millstein are co-teaching a seminar class at UCLA in Fall 2016 on "Verification, Synthesis, and the Creative Habit" to jump-start a formal graduate class.  We hope to
produce future network engineers with interdisciplinary skills in verification
and programming languages.
%Those core
%courses are taken by both programming languages students and students
%in other disciplines to cover PhD breadth requirements.  
%By
%demonstrating how PL techniques can be used to facilitate software
%development in other domains, we hope to increase engagement of
%students from other disciplines.

{\bf Outreach:} Finally, the PIs have a history of engaging women and under-represented minorities in
their research projects and will continue to seek out opportunities to
do so.  For example, PI Walker has mentored two winners of the CRA
outstanding undergraduate award, and both happened to be
under-represented minorities in computer science: one an African
American student and one a woman.  The former, Lester Mackey, went
gone on to get his PhD in computer science, and the latter, Katherine
Ye, will be entering graduate school in Fall 2016.   Varghese has mentored several women, including
co-advising Lili Qiu (now a professor at UT Austin) and Lavanya Jose (currently a graduate student at Stanford).


\section{Current Propane Language and Architecture}
\label{sec:propane}

\begin{figure}[t]
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{figures/datacenter-topo}
        \caption{Data Center Topology}
        \label{fig:data-center-topo}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \centering
\begin{mylisting}
 1. define Locality = 
 2.   {PL1 | PL2 => always(in)}
 3. 
 4. define NoTransit = 
 5.  {true =>!transit({Peer1,Peer2})}
 6.
 7. define Ownership = 
 8.  {PG1   => end(A)
 9.   PG2   => end(B)
10.   PL1   => end(E)
11.   PL2   => end(F)
12.   true => exit(Peer1 >> Peer2)}
13.
14. define Main =
15.   Ownership & Locality & NoTransit & 
16.   agg(PG, in -> out)
\end{mylisting}
        \caption{Data Center Policy}
        \label{fig:policy}
    \end{minipage}
\end{figure}

Our new ideas for deployable synthesis are best understood in the context of
our preliminary work on \Propane. Reviewers familiar with \Propane may skip to section~\ref{sec:research}, where we describe our proposed new research.  

\Propane allows users to program collections of routers running BGP
by writing down high-level, declarative constraints that 
describe the paths that traffic is allowed to flow along, as well
as the back-up paths to use in case of failure.  These constraints are
remarkably
concise as well as being modular and compositional.
As such, they allow users to construct complex policies
from relatively simpler parts.  In fact, in studies of policy we obtained
for a data center 
and a backbone network from a large cloud provider, we have found that 
realistic
routing policy (not including definitions of prefix groups and ownership of
prefixes) that faithfully expresses the concerns of network operators
can be expressed in as little as 30-50 lines of Propane
code.  In contrast, representing the same policy in low-level BGP 
configurations takes \emph{1000s of lines of code per device}.
Some of this surprising economy of notation comes from the high-level 
abstractions we use
(regular expressions and logical predicates, which may expand exponentially
when converted into lower level abstractions such as deterministic
automata and prioritized tables); some comes from sharing
policy effectively across groups of destinations; some comes from
sharing policy across multiple devices; and some comes from the fact
that our system synthesizes so many low-level details (local preferences,
community values, MEDs, import and export filters per device).  All told, 
the savings make Propane policies vastly
easier to understand, analyze, maintain and modify than traditional
configurations.

\paragraph*{Language.}
As an example, consider the idealized data center topology presented in
Figure~\ref{fig:data-center-topo}.  Here, PG1 and PG2 represent sets
of destination prefixes that supply services to the outside world (G stands
for Global and P for Prefix).  These destinations originate at top-of-rack (TOR)
switches A and B respectively.  PL1 and PL2 are local services originating
at E and F.  The data center owns and controls each of the named switches
A, B, C, \etc, and is connected to the rest of the internet via
two peers, named Peer1 and Peer2, which it does not control, but with
whom it communicates via BGP.

The user of this data center has a number of policy objectives. First,
the local services should not receive traffic from the rest of the internet.  
Lines
1 and 2 of Figure~\ref{fig:policy} express this concern.  They define
a policy named Locality.  Such policies contain clauses of the form
\texttt{$X$=>$P$} where $X$ defines a set of destination prefixes and 
$P$ defines a set of ranked (acyclic) paths along which traffic may flow 
to reach the given destination.  The keyword \texttt{in} refers to
any network location that we control; the constraint \texttt{always($L$)}
defines paths that only use locations in the set $L$.  Hence, line 2
of the policy ensures traffic flowing to PL1 and PL2 comes from within
our data center, not outside it.  Line 5 uses another constraint
\texttt{transit($S$)}, which defines paths between members of the set $S$.
The constraint\texttt{!transit($S$)} takes the compliment of such a set,
and hence lines 4-5 define a policy named \texttt{NoTransit}, which prohibits
traffic from Peer1 to Peer2 (and vice versa) from flowing through our
data center.  The \texttt{Ownership} policy demands that any path
to a given prefix group ends at the appropriate TOR switch.  Finally,
\texttt{Main} is defined as the conjunction of all of the previous constraints,
and in addition, specifies a \emph{control constraint}.  The control
constraint \texttt{agg(PG,in->out)} demands that any announcement
for a more precise prefix, such as PG1 or PG2, be transmitted as the
more general prefix PG along any topology edge between nodes \texttt{in}
our network and nodes \texttt{out}side of our network.

%
%\begin{figure}[!h]
\begin{wrapfigure}{R}{0.5\textwidth}
%\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.45\textwidth]{figures/pipeline}
%\end{minipage}
%
%% \begin{minipage}{.5\textwidth}
%% \begin{code}
%% \end{code}
%%   (b)
%% \end{minipage}
\caption{\Name architecture.
%FE = Front End;
%RIR = Regular expression Intermediate Representation;
%PGIR = Product Graph Intermediate Representation;
%ABGP = Abstract BGP; Quagga/Cisco: Vendor-specific Router Config.
%Languages.
}
  \label{fig:pipeline}
  \vspace{-1em}
\end{wrapfigure}
%\end{figure}
%
\paragraph*{Architecture.}
Figure~\ref{fig:pipeline} presents the architecture of the
current \Name compiler, which takes high-level constraints, such as those
just described, and synthesizes low-level, device-by-device configurations.  
To do so, the compiler transforms the front-end (FE) specifications through
a series of intermediate languages.  The first intermediate language, the
RIR, unfolds definitions such as \texttt{end}, \texttt{transit} and \texttt{always} into raw regular expressions and merges all the constraints for a single
prefix.  

The next step is to combine information about
the user-declared policy with the network topology.
This is achieved by converting regular expressions into deterministic
automata, using standard techniques and then ``intersecting'' the graph
defined by the automaton with the graph defined by the topology.
We call this lower-level graph-based representation the \emph{product graph} (or PGIR).
Intuitively, every node in the PGIR contains both a topology location
(A, B, C, \etc) and an automaton state (q1, q2, q3, \etc).  There is an
edge from node (A,q1) to node (B,q2) in the product graph if there is
a link in the topology from A to B, and the \Name policy states that
it is legal to progress from automaton state q1 to q2.  Hence,
the key property of the PGIR is that any path from start to final state
\emph{both} obeys the constraints of the topology and the constraints
of the user policy.  As a consequence, the compiler may perform any
analyses that depends on both topology and policy using this representation:  
it may determine whether node A can be reached from node B; it can determine
what the effect of failing a particular link or topology node has on 
connectivity; and it can determine whether BGP can implement the policy
faithfully (not all product graph policies can be implemented faithfully).

Once various analyses have been performed on the product graph, it is
transformed into abstract BGP (ABGP), a vendor-agnostic variant of BGP.
From there, configurations for individual devices may be generated in
vendor-specific formats such as Cisco or Quagga formats.

\paragraph*{Related Work.}
The \Propane system and language design is inspired by past work on many 
recent SDN programming
languages~\cite{frenetic,pyretic,flowlog,foster:merlin,netkat,kinetic,pga}.
However, several significant differences stand out:  (1) the ability to express
both intra-domain routing and \emph{inter}-domain routing is missing in
previous SDN languages: 
(2) the ability to express routing \emph{preferences} and 
\emph{back-up paths} is missing in
previous SDN languages;
and (3) the ability to compile to fully distributed control plane
protocols such as BGP, which need no centralized controller, which
scale to the largest networks, and which fail and recover locally.

Another related system is SDX, the software-defined exchange 
point~\cite{sdx,isdx}. This project involves design of a route server, which 
composes the routing policy from
many neighboring networks, which each exchange traffic
with one another.
In contrast, the goal of \Propane is to support high-level 
specification of routing policy for \emph{one}
network.  Because
\Propane compiles to traditional distributed protocols (BGP) as opposed to
to infrastructure managed by a centralized route server, 
\Propane's compilation and synthesis algorithms
are completely different from those used in SDX.

RPSL~\cite{rpsl}, Nettle~\cite{nettle} and DADC~\cite{dadc} are three
other languages designed to routing policy for distributed control planes
running legacy protocols.  RPSL uses attribute-value pairs to specify policy,
Nettle embeds router specifications in Haskell, and DADC uses logic programming
and SAT to infer parameters for configurations automatically and ensure they
are consistent.  \Propane differs from this past work in a number of ways but most
importantly in the kinds of abstractions provided.  In particular, \Propane supplies
a high-level constraint language that allows programmers to specify
network-wide paths and relations between paths.  This lifts the level of abstraction
for programmers and avoids device-by-device configuration.

%% The centralized control planes of SDN, however, are not a panacea.
%% First, while many SDN programming systems~\cite{sdn-languages} provide effective \emph{intra}-domain routing
%% abstractions, allowing users to specify paths within their network,
%% they fail to provide a coherent means to specify \emph{inter}-domain routes.
%% Second, centralized control planes
%% require careful design and engineering to be robust to failures---one must ensure that all devices can communicate with the controller at all times, even under arbitrary failure combinations. Even ignoring failures, it is necessary for the control system to
%% scale to meet the demands of large or geographically-distributed networks,
%% and to react quickly
%% to environmental changes. For this challenge, researchers are exploring
%% multi-controller systems with interacting controllers, thus bringing back distributed
%% control planes~\cite{mccauley2013extending,onos} and their current programming difficulties.
%% In addition, academic
%% language design and implementation efforts have not kept pace.  For instance, work on many
%% experimental SDN languages~\cite{frenetic,flowlog,vericon,merlin,netkat,kinetic,pga} has not yet shown how to implement fault tolerant
%% multi-controller systems that support their high-level abstractions efficiently.



\section{Research Agenda}
\label{sec:research}

The initial \Name prototype provides a preliminary platform that
the PI will use to support a wide range of research on distributed control
plane specification, programming, synthesis, transformation and verification that we now detail.

\subsection{Policy Specification Abstractions}

\begin{wrapfigure}{R}{0.15\textwidth}
  \centering
  \includegraphics[width=.1\textwidth]{figures/abstract-topo}
\caption{Abstract topology with multiplicities.}
  \label{fig:abstract-topo}
  \vspace{-1em}
\end{wrapfigure}

\paragraph*{New Topological Abstractions.}
In the previous section, we gave an example of a \Name{} policy for
controlling data center routing.  In that example, the network operator
referred to individual switches by name (A, B, C, \etc).  However,
this idealized example involved a network with only 10 switches.  In
contrast, real data centers may have hundreds of switches.  In order to
manage networks at this scale, it is not effective to define policy in
terms of individual devices.  Operators must think 
in terms of \emph{groups} of devices that have similar roles:  top-of-rack switch,
tier-one switch, \etc.  Moreover, in order to plan policy and reason about
fault tolerance, they rely on \emph{invariants} pertaining to the 
connectivity properties of these groups.  
In order to support operators for large networks, we will extend
\Name's specifications and programming process to support
new topological abstractions of this kind.

One interesting source of inspiration for topology abstractions is,
perhaps surprisingly, the
\emph{memory analysis literature} from the programming languages 
community (\eg, Sagiv \etal~\cite{sagiv+:shape-analysis}).
Memory analysis (and alias analysis) involves analyzing programs
and inferring the shapes (often variations on lists, trees and graphs)
of data structures.  In order to make memory analysis tractable, 
the potentially infinite number of memory shapes must be collapsed into
some tractable representation.  Similar representations may be used for
describing network structures, which like program memory are structured
graphs. In particular, we believe memory
abstractions involving \emph{multiplicities} may form an effective and
novel foundation for describing classes of networks. 

As an example, consider again the data center topology presented in
Figure~\ref{fig:data-center-topo}.  This topology has three tiers of
switches, and connectivity between the layers follows fixed rules,
as is commonly the case.  In order to represent such a network,
we can represent all nodes in each tier using a single, abstract group
node, and we can represent the edges between nodes using multiplicities.
Figure~\ref{fig:abstract-topo} presents one way of doing this.
Here abstract topology node T represents the set of concrete nodes
A, B, E and F --- T plays the ``role'' of top-of-rack switch.  Likewise,
U represents concrete nodes C, D, G and H and V represents X and Y.
Each edge in the abstract topology is annotated with 
Here the multiplicity \texttt{2} annotated on the edge from T to U but closer
to T indicates there are two edges extending from \emph{each} node
represented by T.  Likewise, the 2 annotating the edge coming
in to U from T represents the fact that each U node has 2 connections
to each T node.  The \texttt{*} muliplicities indicate that all nodes
represented by U are connected to all nodes represented by V and vice
versa.  The reader can verify that the concrete topology satisfies the
stated invariants --- a first research task is to develop efficient algorithms
that can check such invariants automatically in the general case.

\begin{wrapfigure}{R}{0.4\textwidth}
  \centering
  \includegraphics[width=.35\textwidth]{figures/extended-topo}
\caption{Extended data center topology.}
  \label{fig:extended-topo}
  \vspace{-1em}
\end{wrapfigure}
There are a variety of ways to use such abstractions in the process of
programming, synthesis, maintanence and verification.  As mentioned above,
such abstractions more closely match current operator practice when
reasoning about and planning data center policy.  In addition, such
abstractions can capture \emph{classes} of concrete network topologies.
For instance, if we wanted to extend our data center with an additional pod,
as shown in Figure~\ref{fig:extended-topo}, we could do so and 
the extended topology also
matches the given abstract topology.  Consequently, a policy written in
terms of our abstract topology could be applied to \emph{either} concrete
data center topology.  This fact means that it is possible to work hard
to get routing policy right \emph{once} but then potentially \emph{reuse} that
work effectively over many data centers with related shapes, or when more
equipment is provisioned in an existing data center.  In essence,
such abstractions provide a new kind of modularity for network programs.

Of course, to capture rich classes of networks with a variety of
different kinds of striping patterns, inter-connections, and connectivity
invariants
we will likely need many more different kinds abstractions than are
shown in Figure~\ref{fig:abstract-topo}.  In particular, when we examine 
topologies other than fat trees~\cite{al-fares:data-center-architecture,f10},
Quasi Fat-Trees~\cite{quasi-fat-trees}, Aspen trees~\cite{aspen-trees}, DCell~\cite{dcell}, Jellyfish~\cite{jellyfish}, and more,
we believe we many need multiplicities on nodes (constraining the
number of nodes in an abstract node or pod), relations between 
multiplicities ($m \leq n$
to ensure each of $n$ nodes are connected by $m$ paths to other parts of
a data center), probabilistic relations (to describe randomized network
designs like Jellyfish~\cite{jellyfish}) and perhaps nested abstractions, to describe the
hierarchical structure of some data center designs such as DCell~\cite{dcell}.  

\paragraph*{Compilation and analysis with abstract topologies.}
Our new abstractions will also be an important component of the implementation
infrastructure of \Name. 
Many large cloud providers, such as Microsoft, define policy based on
\emph{templates}, with one template for each role or abstract group of
routers.  The parameters of each template may be instantiated to generate
concrete router configurations for each router in the group.
Indeed, there are a variety of tools available, such as Hatch~\cite{hatch}
and Thwack~\cite{thwack} 
to help with the definition and sharing of such templates.
In order for \Name to exploit existing template-based infrastructure,
it will be necessary to upgrade \Name's compilation algorithms so
that policy expressed over abstract topologies generates appropriate
templates rather than concrete configurations.  Generating templates will
also help network operators validate the output of the \Name compiler:
they will only have to examine a small number of template files, one for
each role, rather than one for each device.

Finally, while writing policy over abstract topologies is attractive
for its simplicity and the potential for reuse, it also adds a variety 
of technical challenges.  In particular, to determine whether a network
policy is ``good,'' we typically need to analyze it for a variety of
properties.  For instance, we would like to know whether two destinations
are reachable from one another, or for security purposes, whether
two destinations are isolated from another, or how many failures
it takes to partition a network or make certain destinations unreachable.
One the positive side, abstract topologies are much smaller than concrete
topologies --- this may be a massive advantage, allowing sophisticated 
analyses to execute much more quickly on massive networks.  However, the
abstractions also makes the analysis algorithms more challenging, as they
are now proving properties over entire \emph{classes} of networks instead of
individual \emph{concrete} networks.  We believe we will be able to exploit
ideas from the field of \emph{abstract interpretation}~\cite{cousot+:ai} (the subfield of
programming language research that deals with the science 
of analyzing abstract structures) in defining our algorithms and in proving
them correct.  It will take significant practical and theoretical
research to develop, implement, test and prove correct the necessary 
algorithms for fault tolerance, reachability and security analysis.


\paragraph*{Related research.}
In terms of related research, the closest overlap is with the 
Condor project~\cite{condor}.  However, Condor focused on description
of topologies and then generation and testing of a finite number of
sample topologies with a goal of discovering new topologies that might be 
deployed in next-generation data centers.
In contrast, our work will integrate abstract topologies into the
network programming process. Unlike Condor,
we will develop
compiler algorithms that generate router configuration templates from
abstract topoplogies and operator-level policy.  We will also 
study algorithms for verifying \emph{universal}
fault tolerance and reachability properties---\ie, properties that
hold \emph{for all} concrete
networks that inhabit a given class of topological abstractions.  Such
universal properties provide strong guarantees for classes of
related networks and future-proof networks
that may be expanded.  
Pyretic~\cite{pyretic} and NetKAT~\cite{fast-compiler} also contain sublanguages
that enable virtual networking, but their abstractions do not describe
connectivity invariants and their compilers do not perform analyses over
abstract networks or generate template-based router configurations.

Recent work on network ``symmetry and surgery''~\cite{bjorner+:scaling-network-verification} focused on verifying reachability properties of very large
data centers networks by using a collection of transformation rules to 
transform a large data center network into
a related, smaller network and then by proving a similarly transformed
logical formula is true of the smaller network.  Some of the abstractions
developed here may be useful in our work, but the authors do not consider
the multiplicity-based abstractions that we propose and which seem useful
for verifying fault tolerance properties (\eg, by counting disjoint paths).
While the authors consider verification, they do not consider using
abstract topologies to support compilation or synthesis
of new configurations from high-level specifications.


\paragraph*{Summary of key research questions:}

\begin{itemize}
\item What abstractions help us summarize properties network topologies?
Multiplicities on edges?  On nodes?  Constraints between multiplicities?
Do we need hierarchical abstractions?  Probabilistic abstractions? 
\item How do we write \Name specifications using these abstractions?
\item How do we compile with abstract topologies and make use of templates?  
 How does the compiler perform?
\item How do we analyze properties of network policies, such as
reachability and fault tolerance, over abstract
topologies?  How do these algorithms perform?
\item What theory underpins this research?  What is the formal 
semantics of these abstract topologies?  How do we prove our
compilation algorithms and analyses are correct?
\end{itemize}

\subsection{Expressivity}
A key goal of \Name is to synthesize common policies used by Data Centers and ISPs, many of which are 
detailed in \cite{routingplaybook}.   In particular, we aim to add to \Name the ability to craft policy based on
traffic (in order to reduce billing costs) which is impossible to do in \Propane.
\paragraph*{Traffic Engineering and Inter-domain Routing.}
Many networks have complex business relationships with their peers, providers and 
customers.  Such networks must satisfy agreements to carry traffic while minimizing
cost, thereby maximizing their own profits.  
Currently, Propane users may specify preferences between routes; these
less-preferred routes are utilized only if failures occur.  However,
many users have more sophisticated requirements than this ---
requirements that require cost and network capacity as well as
failures be taken into account.  In particular, to deal with higher
load, bursts, or partial failures, networks may need to open more
costly routes, at least temporarily.

We propose to extend Propane with facilities that allow users to specify the
costs associated with using different interdomain routes, the capacities of these
routes and the obligations they have to customers and peers.  In doing so, there
are a number of design choices to be made.  In particular, should capacity and cost
be associated with the network topology or with the user policy?  How does such
quantitative information interact with the non-quantitative information concerning
routes and failures?  Once the language design choices have been made, we will 
study compilation techniques.  Our current platform compiles to BGP, but BGP 
does not contain mechanisms for processing quantitative information or managing
traffic engineering mechanisms.  Consequently, we propose using a hetergeneous
back-end composed in part of BGP running at the edge, to handle interdomain
routing, and our own custom switch agents, implemented using P4~\cite{P4}, 
to manage the traffic monitoring, shaping, policing and routing needed to implement
cost-aware routing.  

\paragraph*{Triggers and Time-dependent Routing Preferences}

In order to support the large range of policies that real ISPs use, some of which are detailed in \cite{routingplaybook}, we will invent new abstractions in \Name.   We describe two such ideas, both
of which are motivated by policies described in \cite{routingplaybook}.

First, at the highest level, \Propane allows the operator to provide a list of routes ordered by preference and to specify that lower preference routes can be used when more preferred routes fail.  Thus in \Propane failure is the only  stimulus for changing a route.  However, a common paradigm is to allow a new route to take over when the amount of traffic volume on what was a high-preference route exceeds a threshold.  Thus, we are led to invent an abstraction and a language construct called a {\em trigger} which includes failures but also other performance related predicates, analagous to a guard~\cite{guardref} in programming languages.  We will need language constructs to model common performance measures that can be used in such triggers such as latency and traffic volume, and statistical measures such as average and 95th-percentile.

Next, consider two paradigms described in \cite{routingplaybook}.   In the first, that we call a {\em Fusilade} pattern, a client network sends bursts of traffic in sequence to a series of say 5 providers.   Since billing is typically on the 95th percentile based on say 5 minute intervals, if the fusilade switches to a new provider in 1 minutes, each provider will measure 1/5th of the client's overall traffic volume.  

In the second {\em End of Month} pattern, a client has two providers $P1$ and $P2$, and normally splits traffic between them.  However, the client has a minimum amount of traffic that it is charged for every month by say provider $P2$.   Thus by the end of the billing period (say a month), if the total traffic from the client to the provider falls below this floor, the client should exclusively use provider $P2$ until the bound is exceeded.

It appears to be possible to synthesize both these policies by adding an {\em Optimizer} front-end to the architecture of \Propane that takes as input measured traffic in the past (and predictions for the future), and some choice of objective functions (for example, minimize billed cost).  The Optimizer outputs a set of time-indexed route preferences for a back-end such as the current \Propane system.   Note that while Triggers allow users to manually specify route preference based on performance, the optimizer allows such route preferences to be synthesized automatically.

\paragraph*{Related research.}
When it comes to implementing traffic engineering constraints generated from
our proposal, we will exploit
the vast literature in traffic engineering technology~\cite{?,?}.  From a programming language
design perspective, the closest related work is the Merlin language~\cite{foster:merlin}.  Merlin
combines regular routing specifications with formulae that describe minimum and maximum
bandwidth guarantees.  Merlin does not consider the interaction of traffic engineering
specifications with faults, with business costs, or with inter-domain routing objectives.  
Such interactions will lead to different language designs and different implementation
strategies (which mix BGP with traffic engineering mechanisms, for instance).

\paragraph*{Summary of key research questions:}

\begin{itemize}
\item What abstraction boundaries (such as the interface to an optimization layer) can cleanly separate quantitative aspects of policy specification based on costs and traffic volume from non-quantitative aspects such as restricting or preferring certain routes as in \Propane today.
\item Do we need probabilistic abstractions given that the effectiveness of traffic engineering is often analyzed  using probabistic models?  Can we benefit from recent progress in probabilistic verification such as Probabilistic NetKAT.
\item How do we define a specification language that combines inter-domain
routing objectives, fault tolerance and traffic engineering?  How
should we implement such combined specifications?
\item It is well known that even the simplest dynamic changes in BGP can lead to timer interactions (for example in Route Flap damping~\cite{routeflapdamping}.  How do we steer away an automatic optimizer from such perils?
\item What is the formal 
semantics of mixing quantitative and non-quantitative modules?  How do we prove our
compilation algorithms and analyses are correct?
\end{itemize}

\subsection{Backend Diversity}

Currently, the \Name prototype compiles high-level specifications into BGP
configurations.  However, other protocols offer a range of other properties
such as better convergence times or load balancing that network operators 
will want to exploit.

\paragraph*{Traditional Protocols.}  Most networks will use
eBGP to communicate with neighboring networks and 
then iBGP, OSPF or another IGP protocol to distribute routes internally.
While BGP operates using local preferences, regular expression filters,
and shortest paths based on path lengths, some protocols such as OSPF
use real-valued link weights to compute shortest paths, which are not
supported in \Name.  In addition, in order to support scalability, 
an OSPF network may be divided into separate \emph{areas} that only selectively
export shortest paths information --- here, there is a tradeoff between 
convergence time and finding optimal paths.  

In order to
augment \Name so that it can process additional procotols, we will
need to upgrade our intermediate languages to enable representation 
of these additional features (\eg, link weights, OSPF areas, static routes,
route redistribution, \etc).  
Some additional challenges include deciding exactly which protocols should be used,
as well as how and where
a synthesis algorithm should divide a network into areas.  We will also
explore extensions to the \Name front end language to give users
control over such features.

In addition to changing our intermediate representation, we will also need to 
change our internal safety analysis algorithms to reflect the semantics of 
link weights, OSPF and other protocols.
In addition, our synthesis algorithms will have to manage the interactions
\emph{between} protocols.

\paragraph*{Exploiting Programmable Switches.}

\paragraph*{Related Work.}
ConfigAssure~\cite{narain:lisa05,narain+:configassure}  is another
system designed to help users synthesize
router configurations. However, ConfigAssure does not 
provide the same kind of high-level abstractions as \Name
(regular paths, predicates and abstract topologies) and does not
support inter-domain routing via BGP.  Consequently,
the intermediate languages algorithms used in \Name are quite
different from ConfigAssure, which uses logic programming and SAT.
\Name also provides different domain-specific analyses such as
our fault tolerance analysis.

\paragraph*{Summary of key research questions:}

\begin{itemize}
\item How do we reorganize and extend our intermediate languages to encode and
implement new features of various standard protocols such as link weights
or areas in OSPF?  
\item How do synthesis algorithms decide which protocols to use and where?
Which properties (convergence time, scalability?) govern these choices?
\item How does the compiler reason about administrative distances
and the interactions of several different protocols in a single
implementation?
\item Is it possible to exploit the properties of next generation
programmable switches, such as those implementing P4,
to define more complete and efficient implementations of \Name
provided this hardware is available?
\end{itemize}

\subsection{Migration Abstractions and Mixed Verification}

Higher-level policy languages such as provided by the \Name platform provide clear advantages for network understanding, maintenance, and reliability over the low-level style in use today.  While network engineers and operators would like to accrue these advantages, they are also hesitant to convert their networks to a new technology, and quite reasonably so.  It costs significant human time and effort to translate low-level configurations into a higher-level policy and to ensure that the original functionality and performance is preserved.  Further, an all-or-nothing approach to conversion to \Name is a non-starter for several reasons.  First, it precludes an incremental deployment strategy, whereby subnetworks are converted one at a time.  Second, it precludes a mixed configuration style consisting of both low-level directives and high-level policies.  Such a style allows legacy subnetworks to remain unchanged while enabling new subnetworks to take advantage of \Name.  It also provides an ``escape hatch" for engineers to obtain fine-grained, low-level control over network configuration when the desired behavior is not (easily) expressible in \Name.  

In our discussions with network engineers it has become clear that these issues are key barriers to practical deployment of new approaches to network configuration.  To address them, we plan to develop tools to help network engineers to correctly {\em migrate} existing networks to the \Name platform as well as to {\em integrate} the \Name technology with existing approaches to support a flexible, hybrid approach to network configuration.


\begin{figure}
  \centering
  \includegraphics[width=.9\textwidth]{figures/transition-tech-arch}
\caption{\Name verification and transition technology architecture.}
\label{fig:transition-tech}
\end{figure}

\paragraph{Migration}  Figure~\ref{fig:transition-tech} shows a proposed architecture for tool-supported migration to the \Name platform.  The basic idea is to compare the current low-level network configuration against a candidate \Name policy for the network, automatically providing example packets on which the two policies differ.  The engineer can use this information to iteratively revise the candidate \Name policy until it achieves the desired behavior.  Providing such a migration tool will require us to address several technical challenges.  

First, we must convert both the low-level configurations and higher-level policy to a common format.  As shown in the figure, we plan to use our graph-based PGIR format for this purpose, as it makes explicit the allowed paths through the network.  While conversion from vendor-specific configurations to the vendor-neutral ABGP format should be straightforward, the conversion from ABGP to PGIR is non-trivial due to the expressiveness and potential complexity of BGP policies.  In particular, it does not suffice to simply ``invert" \Name's current translation from PGIR to ABGP, since that translation generates stylized ABGP configurations which in our experience differ in important ways from manually written configurations.  We will instead identify common BGP idioms that network engineers use to enforce different aspects of network behavior and then develop translation strategies that target these idioms.  We may also be able to leverage a comprehensive model of low-level configurations that was developed in our prior work~\cite{}.

Second, we must convert the two resulting PGIRs into a set of logical axioms that is suitable for automatic analysis by modern Satisfiability Modulo Theories (SMT) solvers such as Z3.  We can then ask the SMT solver to prove that the two policies are equivalent or otherwise produce a counterexample, which corresponds to a packet that is treated differently by the two PGIRs.  We also determine the full path the network that the packet takes under each policy and present that to the user, allowing him to easily understand the differences and make appropriate changes to the \Name policy.

One downside of the proposed approach is that it requires the engineer to devise an initial \Name policy manually, which the migration tool then helps to iteratively improve.  We will therefore also consider approaches to {\em infer} a \Name policy directly from the given low-level configuration.  Since \Name policies employ regular expressions to specify allowed paths, it is natural to leverage existing approaches to learning regular expressions from examples.  For example, the L* algorithm learns regular expressions given a ``teacher" that can answer membership and equivalence queries~\cite{}.  In our setting, we can simulate the teacher by querying the PGIR representation of the low-level configuration, as well as by interaction with the user.  We will likely need to extend existing learning algorithms to handle other aspects of \Name, such as its support for prioritized paths.

\paragraph{Mixed Verification} There are several challenges in supporting a mixed form of configuration, whereby some portions of the network behavior are specified with \Name and some using existing technologies.  Currently the \Name platform guarantees by construction that produced low-level configurations faithfully implement the high-level policy, and furthermore that this policy will be respected in the face of arbitrary failures.  The inclusion of existing low-level configurations for some portions of the network significant complicates the ability to provide these guarantees and any others that we may want to augment the platform to support. First, the \Name compiler has less flexibility because it must retain the given low-level configurations as is.  Second, the \Name platform must be able to reason about the network as a whole despite the fact that portions are manually configured.

To address these challenges we plan to adapt ideas from the literature on compositional program analysis and verification.  In particular we will leverage the notion of {\em assume-guarantee reasoning}, which allows components to be analyzed separately in order to ensure global properties of interest.  In our setting, we require {\em interface specification} for the manually configured portions of the network.  The \Name platform then can {\em assume} that these specifications holds when reasoning about the network as a whole and compiling the \Name-specific portions.  Separately, we must {\em guarantee} that the manually configured portions indeed meet their interface specifications.

Several questions must be answered to make this approach effective and practical.  What is the form of interface specifications?  How are they produced?  How are they verified?  How must the \Name platform's analysis and compilation algorithms be modified to accommodate these specifications?  As a first cut, a natural choice is for interface specifications to be written in the \Name policy language itself.  We can then leverage similar ideas as described above in the context of migration in order to produce and/or validate these specifications relative to existing low-level configurations.  

However, in the migration setting the goal is to infer {\em equivalent} \Name policies for low-level configurations.  In contrast, here that goal may not be possible due to expressiveness limitations of \Name, and furthermore it is not desirable even if it is possible. Rather, 
the goal is to identify an 
{\em abstraction} of the low-level configurations that is expressible in \Name, relatively simple to reason about, yet precise enough to allow the platform to compile the remaining \Name policy while providing strong correctness guarantees.  Here we can leverage a wealth of ideas from the program analysis community on sound forms of abstraction for various properties of interest (e.g., overapproximations vs. underapproximations), along with techniques such as counterexample-driven refinement for incrementally improving candidate abstractions.


As a simple example, consider a subnetwork whose low-level configurations involve a sophisticated load balancing scheme via a form of multipath routing.  It is not useful to attempt to exactly represent this complex scheme in the language of \Name, and indeed it may not even be possible.  Rather, it suffices for the \Name policy to express the {\em possible} paths that each packet can take, along with any backup paths to use in the case of failures.

Finally, given an appropriate interface specification for manually configured portions of the network, we must generalize the \Name compilation strategy to incorporate the assumption that those portions meet their specifications as well as the constraint that those configurations cannot be modified.


\paragraph*{Related research:}  \tdm{Shriram Krishnamurthi has some work on migration to SDN in the SDN workshop 2015.  What else?}


\paragraph*{Summary of key research questions:}

\begin{itemize}
\item How can we faithfully translate low-level configurations into a format that is amenable to comparison with \Name policies?

\item How can we automate this comparison and provide feedback that enables users to refine their policies?

\item Can we leverage machine learning techniques to infer \Name policies directly from low-level configurations?

\item What form of interface specification is necessary for a manually configured subnetwork, in order to support \Name analysis and compilation?

\item In what way should that interface abstract the behavior of that subnetwork in order to ensure end-to-end correctness?

\end{itemize}


\begin{wrapfigure}{R}{0.5\textwidth}
  \centering
  \small
  \begin{tabular}{|l|l|l|l|}
\hline
Protocol & Feature & ARC~\cite{arc} & Proposal \\\hline
OSPF & Single area & Yes & Yes \\
& Standard area & No & Yes \\
& Stubby area  & No & Yes \\
& Totally stubby area  & No & Yes \\
& Not so stubby area  & No & Yes \\\hline
RIP & & Yes & Yes \\\hline
eBGP & Shortest path &  Yes & Yes \\
  & Local pref & No & Yes \\
  & Regexp filters &  No & Yes \\
  & Community tags & No & Yes \\\hline
iBGP & & ? & Yes \\\hline
Redistrib. & Acyclic & Yes & Yes \\
  & Cyclic & No & Yes \\
%Aggregation & Black holes & No & Maybe \\
\hline
  \end{tabular}
\caption{Extended control-plane verification proposal.}
\label{fig:smt-vs-arc}
\end{wrapfigure}


%% \section{Related Work}

%% To reduce configuration errors, operators are increasingly adopting an
%% approach in which common tasks are captured as parameterized templates~\cite{hatch,thwack}.
%% %
%% %More powerful still are systems like
%% %ConfigAssure~\cite{narain:lisa05,narain+:configassure}, which use SAT solving
%% %and model finding tools to fill in parameters in configurations while
%% %ensuring key correctness constraints are satisfied.
%% %One step further, systems like
%% %ConfigAssure~\cite{narain:lisa05,narain+:configassure} use SAT solving
%% %and model finding tools to correctly and consistently fill in some parameters.
%% %
%% While templates help ensure certain kinds of consistency across devices,
%% they do not provide fundamentally different abstractions from existing configuration languages
%% or bridge the semantic divide between network-wide policies and device-level configuration.
%% %They do not provide fundamentally different abstractions
%% %from existing configuration languages and
%% Thus, they still require operators to
%% manually decompose policies into device behaviors and to reason manually about the interaction of different
%% protocols.

%% As a complementary approach, configuration analysis tools can help
%% reduce misconfigurations by checking if low-level configurations match
%% high-level policy~\cite{batfish,feamster+:rcc}. However, such tools, while
%% an important component of any network management system,
%% cannot, on their own, help operators with the challenging task of generating
%% configurations in the first place.

%% %Further, today's tools cannot verify correctness under concrete failure scenarios, rather than under all possible failures.

%% Software-defined networking (SDN) and its abstractions
%% are, in part, the research
%% community's response to the difficulty of maintaining policy
%% compliance through distributed device interactions~\cite{ethane}.
%% Instead of organizing networks around a distributed
%% collection of devices that compute forwarding tables through
%% mutual interactions, the devices are told how to
%% forward packets by a centralized controller. The controller is responsible for ensuring that the
%% paths taken are compliant with operator specifications.
%% %Researchers
%% %have developed increasingly sophisticated languages that let operators
%% %specify desirable network paths~\cite{x,y,z} which are then translated
%% %to forwarding tables at runtime.



\section{Broader Impacts of the Proposed Work}
\label{sec:impact}

The proposed work, if successful, has the potential to transform the way
that thousands of networks in the US and all over the world are managed.
By developing higher-level, correct-by-construction abstractions for
network operators, and creating a path to deploy those abstractions
in real networks, the \Name platform will decrease
errors in network policy design and implementation, and subsequently
to decrease network downtime and vulnerability to attack.  However,
for maximum impact, we need to engage in both industrial outreach and
educational activities.

\paragraph*{Industrial Outreach.}
In 2016, the networking and programming languages
researchers at Cornell and Princeton universities came together
to form the Cornell-Princeton Center for Network 
Programming (CNP)~\cite{center-for-network-programming}.
While there is a large an vibrant networking community on the US
West Coast, centered in the Bay Area, there was no such community on
the US East Coast.  The CNP was formed to create such a community.

Our first major event was a 1-day workshop held in June 2016 at
Cornell Tech in New York.  It included roughly 50 participants from
academia and a wide array of businesses in the New York area including
Cisco, Juniper, Huawei, Intel, Goldman Sachs, Verizon, Google, Amazon,
Yahoo and many more.  The workshop included technical presentations by
academics, panel discussions with industry experts, and many breaks to
facilitate small group conversation.  The workshop fulfilled its aim
of allowing academics and industry to exchange problems and solutions,
vision for the future, and contact information for follow-up
discussions. We propose to organize a future meeting of this form
under the CNP umbrella and the auspices of this grant.  PI Walker will
organize the logistics and PIs Varghese and Millstein will attend and
give talks on their research, bringing their West Coast ideas out
East.

\paragraph*{Educational Initiatives.}
In addition to disseminating our ideas to industry today,
we need to begin educating the network operators and engineers 
of tomorrow.  Such engineers will need a mix of skills that include
both knowledge of networking protocols and knowledge of formal methods.
With that in mind, we plan to develop new modules for networking courses
at both the graduate and undergraduate level.  Such modules will have
several goals:

\begin{itemize}
\item To teach both low-level mechanisms and high-level abstractions.
\item To emphasize the principles that make the high-level abstractions.
\item To introduce a range of \emph{rigorous}, \emph{formal} properties of
 interest.
\item To expose to students to basic algorithms for verification of such
properties.
\end{itemize}

In addition to teaching concepts, we will give students hands-on
experience writing policy using our language and verification tools.  
More specifically, we plan to develop online tutorials for our tools
that we can use in our classes.  To do so effectively, we will
integrate our work with the CORE simulator~\cite{core}.  CORE
will allow students to visualize, experiment with, and test their
use of our specification language and verification tools.

In addition to traditional in-classroom teaching, the PIs have a strong 
track record of mentoring
undergraduate research projects.
The PIs will also
investiage the use REUs to provide additional undergraduate opportunities
and more time to develop the ideas.
When appropriate, 
the PIs also plan to pair interested graduate students with undergraduate 
students.  This provides the undergraduate with
an additional helping hand and teacher, and the graduate student with
some experience mentoring a younger student.  

\paragraph*{Under-represented minorities.} The PIs are dedicated
to, and have a track-record of, providing opportunities to under-represented 
minorities.  For instance, two of Walker's past undergraduate advisees,
Lester Mackey (African American) and Katherine Ye, won the CRA undergraduate 
outstanding undergraduate
research award.  Both PIs have also mentored numerous graduate students from 
under-represented groups.

\section{Results from Prior NSF Support}
\label{sec:prior-support}

\noindent
{\bf David Walker, PI. NSF CNS-1111520, Intellectual Merit:}
In NSF CNS-1111520, \emph{High-Level Language Support for Trustworthy Networks}
(\$1,400,000, 08/11-08/16),
PI Walker and his collaborators developed new languages, interfaces
and systems for managing software-defined networks (SDNs).  
This project produced the Frenetic family
of network programming languages, the first high-level languages for
programming software-defined networks.  These languages, which include
Frenetic~\cite{frenetic}, 
Pyretic~\cite{pyretic},
NetKAT~\cite{netkat} and others, all adhere to the
\emph{principle of compositionality}, a key design element missing
from earlier network programming languages.  They also invented the
notion of consistent network update~\cite{reitblatt+:consistent-updates},
which ensures key safety invariants are preserved across network update.
Open source code for compilers produced by this project is available
at \url{frenetic-lang.org}.

\noindent
{\bf NSF CNS-1111520, Broader Impacts:} 
The Pyretic programming language was used in Nick Feamster's popular
SDN MOOC and was used to teach tens of thousands of students and
network operators all over the US.  Thanks to its inclusion in this
MOOC, thousands of students have downloaded and used Pyretic.  The PIs
also helped create the P4 switch configuration language, which is
becoming an industry standard.

\medskip
\noindent
{\bf Todd Millstein, PI. NSF CNS-1161595, Intellectual Merit}: In NSF CNS-1161595, {\em NeTS: Medium: Collaborative Research: Systematic Analysis of Protocol Implementations} (\$446,860, 5/12--4/17), PI Millstein and collaborators developed techniques for automatically testing and verifying properties of network protocols and configurations.  Our PIC tool leverages and extends symbolic execution techniques to automatically identify subtle interoperability errors in network protocol implementations~\cite{DBLP:conf/nsdi/PedrosaFKGMM15}.  In other work we developed a novel logical model of a network's control plane and used it as the basis for Batfish, a tool that verifies properties of low-level network configurations~\cite{batfish}.  This award also partially funded Millstein's work on the Propane network programming language~\cite{beckett+:propane}. 

\noindent
{\bf NSF CNS-1161595, Broader Impacts:} The PIC and Batfish tools and Propane language are all publicly available and open source on Github.  PIC identified several previously unknown interoperability errors in popular implementations of the SIP and SPDY protocols, many of which were fixed by the developers.  Similarly, Batfish identified dozens of misconfigurations in the campus networks of two large universities as well as the data-center networks of a large cloud provider, many of which were fixed by the network engineers.

{\bf George Varghese:}: George Varghese has not had NSF support in the last 5 years during his stint in industry.  Before that, he was awarded 10 NSF grants which have led to netwoirking innovations such as Deficit Round Robin, IP lookups, and automated worm fingerprinting.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "proposal.tex"
%%% TeX-PDF-mode: t
%%% End:
